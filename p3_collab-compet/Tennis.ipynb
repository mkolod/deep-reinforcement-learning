{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis_Linux/Tennis.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.0\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "Score (max over agents) from episode 3: 0.0\n",
      "Score (max over agents) from episode 4: 0.0\n",
      "Score (max over agents) from episode 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ou_noise import OUNoise\n",
    "from utils import hard_update, soft_update\n",
    "from replay_buffer import ReplayBuffer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "    def __init__(self, \n",
    "                 in_actor,\n",
    "                 hidden_in_actor=256, \n",
    "                 hidden_out_actor=256,\n",
    "                 out_actor=2,\n",
    "                 leak=0.01, \n",
    "                 seed=42):\n",
    "        \"\"\" Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            in_actor (int): Size of state tensor\n",
    "            hidden_in_actor (int): Number of hidden units in FC layer 1\n",
    "            hidden_out_actor (int): Number of hidden units in FC layer 2           \n",
    "            out_actor (int): Size of action tensor\n",
    "            seed (int): Random seed                    \n",
    "            leak (float): the leak rate for leaky ReLU, i.e. the alpha in (x < 0) * alpha * x + (x >= 0) * x\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.leak = leak\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_actor, hidden_in_actor)\n",
    "        self.fc2 = nn.Linear(hidden_in_actor, hidden_out_actor)\n",
    "        self.fc3 = nn.Linear(hidden_out_actor, out_actor)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(in_actor)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Initialize FC layers followed by leaky ReLU using Kaiming He's (2015) approach.\n",
    "        Source: https://arxiv.org/pdf/1502.01852v1.pdf\n",
    "        For more info see here:\n",
    "            https://www.jefkine.com/deep/2016/08/08/initialization-of-deep-networks-case-of-rectifiers/\n",
    "        \"\"\"\n",
    "        torch.nn.init.kaiming_normal_(\n",
    "            self.fc1.weight.data,\n",
    "            a=self.leak, \n",
    "            nonlinearity='leaky_relu',\n",
    "            mode='fan_in')\n",
    "        torch.nn.init.kaiming_normal_(\n",
    "            self.fc2.weight.data,\n",
    "            a=self.leak,\n",
    "            nonlinearity='leaky_relu',\n",
    "            mode='fan_in')\n",
    "        torch.nn.init.uniform_(self.fc3.weight.data,\n",
    "                               -3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\n",
    "#         state = self.bn(state)\n",
    "        x = F.leaky_relu(self.fc1(state), negative_slope=self.leak)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=self.leak)\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "    def __init__(self,\n",
    "                 in_critic,\n",
    "                 hidden_in_critic=256,\n",
    "                 hidden_out_critic=256,\n",
    "                 out_critic=1, \n",
    "                 leak=0.01, \n",
    "                 seed=42):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            in_critic (int): Dimension of each state            \n",
    "            hidden_in_critic (int): Number of nodes in the first hidden layer\n",
    "            hidden_out_critic (int): Number of nodes in the second hidden layer\n",
    "            out_critic (int): Dimension of each action\n",
    "            leak (float): Leakiness of leaky ReLU\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.leak = leak\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(in_critic, hidden_in_critic)\n",
    "        self.fc2 = nn.Linear(hidden_in_critic, hidden_out_critic)\n",
    "        self.fc3 = nn.Linear(hidden_out_critic, out_critic)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Initialize FC layers followed by leaky ReLU using Kaiming He's (2015) approach.\n",
    "        Source: https://arxiv.org/pdf/1502.01852v1.pdf\n",
    "        For more info see here:\n",
    "            https://www.jefkine.com/deep/2016/08/08/initialization-of-deep-networks-case-of-rectifiers/\n",
    "        \"\"\"\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight.data, a=self.leak,\n",
    "                                      nonlinearity='leaky_relu', mode='fan_in')\n",
    "        torch.nn.init.kaiming_normal_(self.fc2.weight.data, a=self.leak,\n",
    "                                      nonlinearity='leaky_relu', mode='fan_in')\n",
    "        torch.nn.init.uniform_(self.fc3.weight.data, -3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\" Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        x = F.leaky_relu(self.fc1(state), negative_slope=self.leak)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=self.leak)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGAgent:\n",
    "    def __init__(self, \n",
    "                 in_actor, \n",
    "                 hidden_in_actor,\n",
    "                 hidden_out_actor,\n",
    "                 out_actor, \n",
    "                 in_critic,\n",
    "                 hidden_in_critic,\n",
    "                 hidden_out_critic,\n",
    "                 out_critic,\n",
    "                 device,\n",
    "                 relu_leak=1e-2,\n",
    "                 seed=42,\n",
    "                 lr_actor=1.0e-2, \n",
    "                 lr_critic=1.0e-2,\n",
    "                 noise_mul=0.1):\n",
    "        super(DDPGAgent, self).__init__()\n",
    "        self.device=device\n",
    "        self.actor = Actor(\n",
    "            in_actor,\n",
    "            hidden_in_actor, \n",
    "            hidden_out_actor, \n",
    "            out_actor, \n",
    "            relu_leak, \n",
    "            seed).to(device)\n",
    "        self.critic = Critic(\n",
    "            in_critic,\n",
    "            hidden_in_critic,\n",
    "            hidden_out_critic, \n",
    "            out_critic, \n",
    "            relu_leak, \n",
    "            seed).to(device)\n",
    "        self.target_actor = Actor(\n",
    "            in_actor, \n",
    "            hidden_in_actor,\n",
    "            hidden_out_actor,\n",
    "            out_actor, \n",
    "            relu_leak,\n",
    "            seed).to(device)\n",
    "        self.target_critic = Critic(\n",
    "            in_critic, \n",
    "            hidden_in_critic,\n",
    "            hidden_out_critic,\n",
    "            out_critic, \n",
    "            relu_leak,\n",
    "            seed).to(device)\n",
    "\n",
    "        self.noise = OUNoise(out_actor, seed=seed, scale=1.0)\n",
    "        \n",
    "        # initialize targets same as original networks\n",
    "        hard_update(self.target_actor, self.actor)\n",
    "        hard_update(self.target_critic, self.critic)\n",
    "\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=lr_actor)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr_critic, weight_decay=1.e-5)   \n",
    "        \n",
    "    def act(self, states, noise_mul=0.1):\n",
    "        self.actor.eval()\n",
    "        with torch.no_grad():\n",
    "            actions = self.actor(states).cpu().data.numpy()\n",
    "        actions += self.noise.sample() * noise_mul\n",
    "        return np.clip(actions, -1, 1)        \n",
    "    \n",
    "    def target_act(self, states, noise_mul=0.1):\n",
    "        self.target_actor.eval()\n",
    "        with torch.no_grad():\n",
    "            actions = self.target_actor(states).cpu().data.numpy()\n",
    "        actions += self.noise.sample() * noise_mul\n",
    "        return np.clip(actions, -1, 1)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.noise.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADDPGAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_agents,\n",
    "        in_actor, \n",
    "        hidden_in_actor,\n",
    "        hidden_out_actor,\n",
    "        out_actor, \n",
    "        hidden_in_critic,\n",
    "        hidden_out_critic,\n",
    "        out_critic,\n",
    "        device,\n",
    "        relu_leak=1e-2,\n",
    "        seed=42,\n",
    "        lr_actor=1.0e-2, \n",
    "        lr_critic=1.0e-2,\n",
    "        replay_buffer_size=int(1e6),\n",
    "        batch_size=64,\n",
    "        gamma=0.99,\n",
    "        tau=1e-3,\n",
    "        update_every=1,\n",
    "        num_updates=1\n",
    "    ):        \n",
    "        in_critic = in_actor * num_agents + out_actor * 2\n",
    "        self.agents = []\n",
    "        self.num_agents = num_agents\n",
    "        self.out_actor = out_actor\n",
    "        self.replay_buffer = ReplayBuffer(num_agents * out_actor, replay_buffer_size, batch_size, seed, device)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "        self.steps = 0\n",
    "        self.update_every = update_every\n",
    "        self.num_updates = num_updates\n",
    "        self.noise_scale = 1.0\n",
    "        for _ in range(num_agents):\n",
    "            self.agents.append(\n",
    "                DDPGAgent(\n",
    "                    in_actor, hidden_in_actor, hidden_out_actor, out_actor,\n",
    "                    in_critic, hidden_in_critic, hidden_out_critic, out_critic, \n",
    "                    device, relu_leak, seed, lr_actor, lr_critic)\n",
    "            )          \n",
    "\n",
    "    def act(self, states, noise_mul=1.0):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        actions = np.zeros((self.num_agents, self.out_actor))\n",
    "        for agent_idx, state in enumerate(states):\n",
    "            state = torch.from_numpy(state).float().to(self.device)\n",
    "            if state.dim() < 2:\n",
    "                state = state.unsqueeze(0)\n",
    "            curr_agent = self.agents[agent_idx]\n",
    "            action = curr_agent.act(state, noise_mul)\n",
    "            actions[agent_idx, :] = action\n",
    "        return actions\n",
    "            \n",
    "    def step(self, states, actions, rewards, next_states, dones):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        self.steps += 1\n",
    "        self.replay_buffer.add(states, actions, rewards, next_states, dones)\n",
    "\n",
    "        if (len(self.replay_buffer) > self.batch_size) and (self.steps % self.update_every == 0):\n",
    "            # reset steps so we don't overflow at some point\n",
    "            self.steps = 0\n",
    "#             print(\"learning\")\n",
    "            for _ in range(self.num_updates):\n",
    "                experiences = self.replay_buffer.sample()\n",
    "                self.learn(experiences, self.gamma)\n",
    "  \n",
    "    def learn(self, experiences, gamma):\n",
    "        \n",
    "        obs_full, actions_full, rewards_full, next_obs_full, dones_full = experiences\n",
    "        print(\"obs_full.shape={}\".format(obs_full.shape))\n",
    "        print(\"stacked_obs_full.shape={}\\n\".format(obs_full.shape))\n",
    "        \n",
    "        for agent_idx, agent in enumerate(self.agents):\n",
    "            \n",
    "            agent.critic_optimizer.zero_grad()\n",
    "            \n",
    "            agent_torch_idx = torch.tensor([agent_idx]).to(self.device)\n",
    "            other_agent_idx = (agent_idx + 1) % 2                  \n",
    "            other_agent_torch_idx = torch.tensor([other_agent_idx]).to(self.device)\n",
    "            \n",
    "            # Select for current agent\n",
    "            obs = torch.index_select(obs_full, 1, agent_torch_idx).squeeze()\n",
    "            actions = torch.index_select(actions_full, 1, agent_torch_idx)\n",
    "            rewards = torch.index_select(rewards_full, 1, agent_torch_idx)\n",
    "            next_obs = torch.index_select(next_obs_full, 1, agent_torch_idx).squeeze()\n",
    "            dones = torch.index_select(dones_full, 1, agent_torch_idx)            \n",
    "            \n",
    "            target_actions = agent.target_act(next_obs)\n",
    "            target_actions = target_actions.squeeze()\n",
    "            \n",
    "#             actions = torch.from_numpy(actions).to(self.device)\n",
    "            target_actions = torch.from_numpy(target_actions).to(self.device)\n",
    "            \n",
    "            print(\"type(target_actions)={}\".format(type(target_actions)))\n",
    "            print(\"net_obs.shape={}\".format(next_obs.shape))\n",
    "            print(\"target_actions.shape={}\".format(target_actions.shape))\n",
    "            target_critic_input = torch.cat((\n",
    "                next_obs_full.reshape(self.batch_size, -1), \n",
    "                target_actions), dim=1).to(device)\n",
    "            print(\"target_critic_input.shape={}\".format(target_critic_input.shape))\n",
    "\n",
    "        \n",
    "#         target_critic_input = torch.cat((next_obs_full.t(),target_actions), dim=1).to(device)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             q_next = agent.target_critic(target_critic_input)\n",
    "        \n",
    "#         y = reward[agent_number].view(-1, 1) + self.discount_factor * q_next * (1 - done[agent_number].view(-1, 1))\n",
    "#         action = torch.cat(action, dim=1)\n",
    "#         critic_input = torch.cat((obs_full.t(), action), dim=1).to(device)\n",
    "#         q = agent.critic(critic_input)\n",
    "\n",
    "#         huber_loss = torch.nn.SmoothL1Loss()\n",
    "#         critic_loss = huber_loss(q, y.detach())\n",
    "#         critic_loss.backward()\n",
    "#         #torch.nn.utils.clip_grad_norm_(agent.critic.parameters(), 0.5)\n",
    "#         agent.critic_optimizer.step()\n",
    "\n",
    "#         #update actor network using policy gradient\n",
    "#         agent.actor_optimizer.zero_grad()\n",
    "#         # make input to agent\n",
    "#         # detach the other agents to save computation\n",
    "#         # saves some time for computing derivative\n",
    "#         q_input = [ self.maddpg_agent[i].actor(ob) if i == agent_number \\\n",
    "#                    else self.maddpg_agent[i].actor(ob).detach()\n",
    "#                    for i, ob in enumerate(obs) ]\n",
    "                \n",
    "#         q_input = torch.cat(q_input, dim=1)\n",
    "#         # combine all the actions and observations for input to critic\n",
    "#         # many of the obs are redundant, and obs[1] contains all useful information already\n",
    "#         q_input2 = torch.cat((obs_full.t(), q_input), dim=1)\n",
    "        \n",
    "#         # get the policy gradient\n",
    "#         actor_loss = -agent.critic(q_input2).mean()\n",
    "#         actor_loss.backward()\n",
    "#         #torch.nn.utils.clip_grad_norm_(agent.actor.parameters(),0.5)\n",
    "#         agent.actor_optimizer.step()\n",
    "\n",
    "#         al = actor_loss.cpu().detach().item()\n",
    "#         cl = critic_loss.cpu().detach().item()\n",
    "#         logger.add_scalars('agent%i/losses' % agent_number,\n",
    "#                            {'critic loss': cl,\n",
    "#                             'actor_loss': al},\n",
    "#                            self.iter)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "        \n",
    "    def save_agents(self):\n",
    "        raise NotImplementedError(\"Saving is not implemented yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 2\n",
    "\n",
    "in_actor = 24\n",
    "hidden_in_actor = 128\n",
    "hidden_out_actor = 64\n",
    "out_actor = 2\n",
    "\n",
    "hidden_in_critic = 128\n",
    "hidden_out_critic = 64\n",
    "\n",
    "out_critic = 1\n",
    "\n",
    "lr_actor = 1e-2\n",
    "lr_critic = 1e-2\n",
    "relu_leak = 1e-2\n",
    "seed = 42\n",
    "\n",
    "gpu_id = 0\n",
    "use_gpu = True\n",
    "device = 'cuda:{}'.format(gpu_id) if use_gpu else 'cpu'\n",
    "\n",
    "batch_size = 64\n",
    "replay_buffer_size = int(1e6)\n",
    "gamma = 0.99\n",
    "tau = 1e-3\n",
    "update_every = 1\n",
    "num_updates = 1\n",
    "\n",
    "meta_agent = MADDPGAgent(  \n",
    "    num_agents,\n",
    "    in_actor, \n",
    "    hidden_in_actor,\n",
    "    hidden_out_actor,\n",
    "    out_actor, \n",
    "    hidden_in_critic,\n",
    "    hidden_out_critic,\n",
    "    out_critic,\n",
    "    device,\n",
    "    relu_leak,\n",
    "    seed,\n",
    "    lr_actor, \n",
    "    lr_critic,\n",
    "    replay_buffer_size,\n",
    "    batch_size,\n",
    "    gamma,\n",
    "    tau,\n",
    "    update_every,\n",
    "    num_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02232587  0.04771298]\n",
      " [ 0.02163291  0.40717682]]\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "states = env_info.vector_observations\n",
    "\n",
    "actions = meta_agent.act(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 done after 13 steps\n",
      "Score (max over agents) from episode 0: 0.0\n",
      "Average score: -0.0003571428491600922\n",
      "episode 1 done after 13 steps\n",
      "episode 2 done after 13 steps\n",
      "episode 3 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 4 done after 32 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 5 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 6 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 7 done after 14 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 8 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 9 done after 14 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 10 done after 13 steps\n",
      "Score (max over agents) from episode 10: 0.0\n",
      "Average score: -2.857141728912081e-05\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 11 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 12 done after 19 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 13 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 14 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 15 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 16 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 17 done after 14 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 18 done after 13 steps\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "obs_full.shape=torch.Size([64, 2, 24])\n",
      "stacked_obs_full.shape=torch.Size([64, 2, 24])\n",
      "\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "type(target_actions)=<class 'torch.Tensor'>\n",
      "net_obs.shape=torch.Size([64, 24])\n",
      "target_actions.shape=torch.Size([64, 2])\n",
      "target_critic_input.shape=torch.Size([64, 50])\n",
      "episode 19 done after 13 steps\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 20\n",
    "\n",
    "num_steps_max = 1000\n",
    "\n",
    "print_every = 10\n",
    "\n",
    "all_scores = np.zeros(num_agents)\n",
    "ctr = 0\n",
    "\n",
    "for i in range(num_episodes):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "    for j in range(num_steps_max):\n",
    "        \n",
    "        ctr += 1\n",
    "        \n",
    "        actions = meta_agent.act(states)\n",
    "#         print(actions)\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        rewards = env_info.rewards        \n",
    "        dones = env_info.local_done\n",
    "#         print(\"states.shape={}\".format(states.shape))\n",
    "#         print(\"actions.shape={}\".format(actions.shape))\n",
    "#         print(\"rewards.shape={}\".format(len(rewards)))\n",
    "#         print(\"next_states.shape={}\".format(next_states.shape))\n",
    "#         print(\"dones.shape={}\".format(len(dones)))\n",
    "        actions = torch.from_numpy(actions).to(meta_agent.device)\n",
    "        meta_agent.step(states, actions, rewards, next_states, dones)\n",
    "        scores += env_info.rewards\n",
    "        \n",
    "        all_scores += env_info.rewards\n",
    "        \n",
    "        states = next_states\n",
    "        if np.any(dones): \n",
    "            print(\"episode {} done after {} steps\".format(i, j))\n",
    "            break\n",
    "            \n",
    "        if j > batch_size and j % print_every == 0:\n",
    "            print(\"episode {}, step {}: done\".format(i, j))\n",
    "    if i % print_every == 0:        \n",
    "        print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))\n",
    "        print(\"Average score: {}\".format(np.mean(all_scores) / ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
